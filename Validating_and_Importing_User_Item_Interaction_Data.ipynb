{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating and Importing User-Item-Interaction Data\n",
    "\n",
    "\n",
    "For the most part the algorithms in Amazon Personalize look to solve different tasks explained here:\n",
    "\n",
    "1. HRNN & HRNN-Metadata - Personalization\n",
    "1. HRNN Coldstart - Personalization that promotes new conten\n",
    "1. Personalized-Ranking - Takes a collection of items and then orders them in probable order of interest using an HRNN-like approach.\n",
    "1. SIMS(Similar Items) - Given one item, what other items are also interacted with by users.\n",
    "1. Popularity-Count - What items are most popular, if HRNN or HRNN-Metadata do not have an answer for the user you query, this is what is returned by default.\n",
    "\n",
    "\n",
    "No matter the use case, the algorithms all share a base of learning on user-item-interaction data which is defined by 3 core attributes:\n",
    "\n",
    "1. UserID - User who interacted\n",
    "1. ItemID - Item the user interacted with\n",
    "1. Timestamp - When did this interaction occur\n",
    "\n",
    "We also support event types and event values defined by:\n",
    "\n",
    "1. Event Type - Categorical label of an event (browse, purcahsed, rated, etc).\n",
    "1. Event Value - Something corresponding to event type that happened. Generally speaking we look to normalized between 0 and 1 for the values over the types. So if there are three phases to complete a transaction (clicked, added-to-cart, and purchased) there would be an event_value for each phase as 0.33, 0.66, 1.0 respectfully.\n",
    "\n",
    "In this particular exercise we will leave event_type and event_value ignored. They can come in handy later but are skipped for the initial POC. \n",
    "\n",
    "## Chosing a Dataset or Data Source\n",
    "\n",
    "As we mentioned the user-item-iteraction data is key for getting started with the service. This means we need to look for use cases that generate that kind of data, a few common examples are:\n",
    "\n",
    "1. Video-on-Demand applications\n",
    "1. E-Commerce platforms\n",
    "1. Social-Media aggregators / platforms\n",
    "\n",
    "There are also a few guidelines for is the problem correctly sized for Personalize, the minimum recommendations are below:\n",
    "\n",
    "* Authenticated users\n",
    "* At least 50 users\n",
    "* At least 100 items\n",
    "* At least 2 dozen interactions for each. \n",
    "\n",
    "Most of the time this is easily attainable, and if you are low in one category, you can often make it up by having a larger number in the other. \n",
    "\n",
    "Generally speaking your data will not arrive in a perfect form for this application and will take some modifications to get structured correctly. This notebook looks to guide you through all of that. \n",
    "\n",
    "To begin with, we are going to use the Last.FM dataset found [here](https://grouplens.org/datasets/hetrec-2011/). This data fits our guidelines with a large number for users, items, and interactions. \n",
    "\n",
    "Next you will use the cells below to create a folder for the example data as well as download the dataset for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘poc_data’: File exists\n",
      "--2020-01-04 19:57:07--  http://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2589075 (2.5M) [application/zip]\n",
      "Saving to: ‘hetrec2011-lastfm-2k.zip’\n",
      "\n",
      "hetrec2011-lastfm-2 100%[===================>]   2.47M  10.8MB/s    in 0.2s    \n",
      "\n",
      "2020-01-04 19:57:08 (10.8 MB/s) - ‘hetrec2011-lastfm-2k.zip’ saved [2589075/2589075]\n",
      "\n",
      "Archive:  hetrec2011-lastfm-2k.zip\n",
      "  inflating: user_friends.dat        \n",
      "  inflating: user_taggedartists.dat  \n",
      "  inflating: user_taggedartists-timestamps.dat  \n",
      "  inflating: artists.dat             \n",
      "  inflating: readme.txt              \n",
      "  inflating: tags.dat                \n",
      "  inflating: user_artists.dat        \n"
     ]
    }
   ],
   "source": [
    "data_dir = \"poc_data\"\n",
    "!mkdir $data_dir\n",
    "!cd $data_dir && wget http://files.grouplens.org/datasets/hetrec2011/hetrec2011-lastfm-2k.zip\n",
    "!cd $data_dir && unzip hetrec2011-lastfm-2k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At present not much is known about the data other than we seem to have many .dat files and a readme. Opening the readme will tell us about the overall structure of this data. This is a step you probably can skip with custom data unless the data source is coming from an external team. \n",
    "\n",
    "Note the data does not seem to be encoded with utf-8 for some reason so it is recommended that you open a terminal and `cat` the file so that you can see the output as Jupyter Lab/Notebooks do not render text documents that are not utf-8.\n",
    "\n",
    "\n",
    "Performing that yielded some interesting stats about the data:\n",
    "\n",
    "```\n",
    "---------------\n",
    "Data statistics\n",
    "---------------\n",
    "\n",
    "    1892 users\n",
    "   17632 artists\n",
    "      \n",
    "   12717 bi-directional user friend relations, i.e. 25434 (user_i, user_j) pairs\n",
    "         avg. 13.443 friend relations per user\n",
    "         \n",
    "   92834 user-listened artist relations, i.e. tuples [user, artist, listeningCount]\n",
    "         avg. 49.067 artists most listened by each user\n",
    "         avg. 5.265 users who listened each artist\n",
    "            \n",
    "   11946 tags  \n",
    "   \n",
    "  186479 tag assignments (tas), i.e. tuples [user, tag, artist]\n",
    "         avg. 98.562 tas per user\n",
    "         avg. 14.891 tas per artist\n",
    "         avg. 18.930 distinct tags used by each user\n",
    "         avg. 8.764 distinct tags used for each artist\n",
    "\n",
    "-----\n",
    "```\n",
    "\n",
    "In this case we are focusing on the users, the artists, and the listening relations so we have 1892, 17632, and 92834 items to meet those, a great volume of data for getting started.\n",
    "\n",
    "The focus on this notebook is again the interactions so we should look to find some data that supports it.\n",
    "\n",
    "\n",
    "```\n",
    "-----\n",
    "Files\n",
    "-----\n",
    "            \n",
    "   * artists.dat\n",
    "   \n",
    "        This file contains information about music artists listened and tagged by the users.\n",
    "   \n",
    "   * tags.dat\n",
    "   \n",
    "        This file contains the set of tags available in the dataset.\n",
    "\n",
    "   * user_artists.dat\n",
    "   \n",
    "        This file contains the artists listened by each user.\n",
    "        \n",
    "        It also provides a listening count for each [user, artist] pair.\n",
    "\n",
    "   * user_taggedartists.dat - user_taggedartists-timestamps.dat\n",
    "   \n",
    "        These files contain the tag assignments of artists provided by each particular user.\n",
    "        \n",
    "        They also contain the timestamps when the tag assignments were done.\n",
    "   \n",
    "   * user_friends.dat\n",
    "   \n",
    "        These files contain the friend relations between users in the database.\n",
    "     \n",
    "-----------\n",
    "Data format\n",
    "-----------\n",
    "\n",
    "   The data is formatted one entry per line as follows (tab separated, \"\\t\"):\n",
    "\n",
    "   * artists.dat\n",
    "   \n",
    "        id \\t name \\t url \\t pictureURL\n",
    "\n",
    "        Example:\n",
    "        707     Metallica       http://www.last.fm/music/Metallica      http://userserve-ak.last.fm/serve/252/7560709.jpg\n",
    "\n",
    "   * tags.dat\n",
    " \n",
    "        tagID \\t tagValue\n",
    "        1       metal\n",
    " \n",
    "   * user_artists.dat\n",
    "   \n",
    "        userID \\t artistID \\t weight\n",
    "        2       51      13883\n",
    "   \n",
    "   * user_taggedartists.dat\n",
    "  \n",
    "        userID \\t artistID \\t tagID \\t day \\t month \\t year\n",
    "        2       52      13      1       4       2009  \n",
    "  \n",
    "   * user_taggedartists-timestamps.dat\n",
    "\n",
    "        userID \\t artistID \\t tagID \\t timestamp\n",
    "        2       52      13      1238536800000\n",
    "\n",
    "   * user_friends.dat\n",
    "\n",
    "        userID \\t friendID\n",
    "        2       275\n",
    "\n",
    "```\n",
    "\n",
    "So right off the bad we now see a problem that although there is data supporting users interacting with just artists, for some reason we only have it stored as a weight not an actual timestamp. \n",
    "\n",
    "It does look like when a user tagged an artist there is a timestamp, so what if we make an assumption that tagging was a positive indicator and we use that data to get started? It seems like a solid approach for the POC, so that is what we are going to do now. \n",
    "\n",
    "The schema for the `user_taggedartists-timestamps.dat` is:\n",
    "\n",
    "| userID | artistID | tagID | timestamp     |\n",
    "|--------|----------|-------|---------------|\n",
    "| 2      | 52       | 13    | 1238536800000 |\n",
    "\n",
    "\n",
    "That looks pretty good for our base. Only the tagID needs to be removed. \n",
    "\n",
    "\n",
    "## Preparing Your Data\n",
    "\n",
    "The next thing to be done is to read the data with Pandas and confirm the data is in a good state, and save it to a CSV where it is ready to be used with Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Pandas library as well as a few other data science tools in order to inspect the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next open the file with Pandas and take a look at the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID\tartistID\ttagID\ttimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2\\t52\\t13\\t1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\t52\\t15\\t1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2\\t52\\t18\\t1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2\\t52\\t21\\t1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2\\t52\\t41\\t1238536800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userID\\tartistID\\ttagID\\ttimestamp\n",
       "0           2\\t52\\t13\\t1238536800000\n",
       "1           2\\t52\\t15\\t1238536800000\n",
       "2           2\\t52\\t18\\t1238536800000\n",
       "3           2\\t52\\t21\\t1238536800000\n",
       "4           2\\t52\\t41\\t1238536800000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv(data_dir + '/user_taggedartists-timestamps.dat')\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that did not work so well, looks like the tab delimiter needs to be specified, attempt 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>tagID</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>15</td>\n",
       "      <td>1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>1238536800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>1238536800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  tagID      timestamp\n",
       "0       2        52     13  1238536800000\n",
       "1       2        52     15  1238536800000\n",
       "2       2        52     18  1238536800000\n",
       "3       2        52     21  1238536800000\n",
       "4       2        52     41  1238536800000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = pd.read_csv(data_dir + '/user_taggedartists-timestamps.dat', delimiter='\\t')\n",
    "original_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks really good here but lets get some extra insights on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 186479 entries, 0 to 186478\n",
      "Data columns (total 4 columns):\n",
      "userID       186479 non-null int64\n",
      "artistID     186479 non-null int64\n",
      "tagID        186479 non-null int64\n",
      "timestamp    186479 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "original_data.infoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>tagID</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>186479.000000</td>\n",
       "      <td>186479.000000</td>\n",
       "      <td>186479.000000</td>\n",
       "      <td>1.864790e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1035.600137</td>\n",
       "      <td>4375.845328</td>\n",
       "      <td>1439.582913</td>\n",
       "      <td>1.239204e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>622.461272</td>\n",
       "      <td>4897.789595</td>\n",
       "      <td>2775.340279</td>\n",
       "      <td>4.299091e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.287204e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>488.000000</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>1.209593e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1021.000000</td>\n",
       "      <td>2203.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1.243807e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1624.000000</td>\n",
       "      <td>6714.000000</td>\n",
       "      <td>887.000000</td>\n",
       "      <td>1.275343e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2100.000000</td>\n",
       "      <td>18744.000000</td>\n",
       "      <td>12647.000000</td>\n",
       "      <td>1.304941e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userID       artistID          tagID     timestamp\n",
       "count  186479.000000  186479.000000  186479.000000  1.864790e+05\n",
       "mean     1035.600137    4375.845328    1439.582913  1.239204e+12\n",
       "std       622.461272    4897.789595    2775.340279  4.299091e+10\n",
       "min         2.000000       1.000000       1.000000 -4.287204e+11\n",
       "25%       488.000000     686.000000      79.000000  1.209593e+12\n",
       "50%      1021.000000    2203.000000     195.000000  1.243807e+12\n",
       "75%      1624.000000    6714.000000     887.000000  1.275343e+12\n",
       "max      2100.000000   18744.000000   12647.000000  1.304941e+12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there is clearly a range of values for all of the columns which is great, the last one to be mindful of is that the timestamp should be in Unix Epoch format. You can learn more about the format here: https://en.wikipedia.org/wiki/Unix_time\n",
    "\n",
    "Let us grab an arbitrary column and convert it to a datetime and confirm that it feels like a reasonable value for the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235862000000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "year 41132 is out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d2aefeb3727a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marb_time_stamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marb_time_stamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutcfromtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marb_time_stamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: year 41132 is out of range"
     ]
    }
   ],
   "source": [
    "arb_time_stamp = original_data.iloc[50]['timestamp']\n",
    "print(arb_time_stamp)\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular value it rendered a year of 41,132... a bit into the future for us, so somehow we parsed it incorrectly. Attempt number 2...\n",
    "\n",
    "JavaScript records time in milliseconds and this is a collection of data from a web application, so divide by 1000 first and see what is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-02-28 23:00:00\n"
     ]
    }
   ],
   "source": [
    "arb_time_stamp = arb_time_stamp/1000.0\n",
    "print(datetime.utcfromtimestamp(arb_time_stamp).strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11pm on Feb 2nd, 2009 feels completely reasonable so now move forward by transforming each row in the dataframe so we do not need t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
